<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Debajyoti Mondal - ACL Anthology</title><meta name=generator content="Hugo 0.68.3"><link href=/website/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/website/css/main.min.8976777c0832d068a49d330764e507857027f1efa3b8501cf349b0e2db7410fc.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/website/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-light bg-light bg-gradient-light shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/website/><img src=/website/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL Anthology</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/website/faq/>FAQ<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/website/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/website/info/contrib/>Submissions<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/website/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-primary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Debajyoti</span> <span class=font-weight-bold>Mondal</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2022.GWF-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G22-1009.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G22-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-G22-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G22-1009/>Feature Transformation for Improved Software Bug Detection Models</a></strong><br><a href=/website/people/S/Shamse-Tasnim-Cynthia/>Shamse Tasnim Cynthia</a>
|
<a href=/website/people/B/B-Roy/>B. Roy</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a><br><a href=/website/volumes/G22-1/ class=text-muted>Global Water Futures 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G22-1009><div class="card-body p-3 small">Testing software is considered to be one of the most crucial phases in software development life cycle. Software bug fixing requires a significant amount of time and effort. A rich body of recent research explored ways to predict bugs in software artifacts using machine learning based techniques. For a reliable and trustworthy prediction, it is crucial to also consider the explainability aspects of such machine learning models. In this paper, we show how the feature transformation techniques can significantly improve the prediction accuracy and build confidence in building bug prediction models. We propose a novel approach for improved bug prediction that first extracts the features, then finds a weighted transformation of these features using a genetic algorithm that best separates bugs from non-bugs when plotted in a low-dimensional space, and finally, trains the machine learning model using the transformed dataset. In our experiment with real-life bug datasets, the random forest and k-nearest neighbor classifier models that leveraged feature transformation showed 4.25% improvement in recall values on an average of over 8 software systems when compared to the models built on original data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2022.GWF-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G22-1014.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G22-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-G22-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G22-1014/>SET-STAT-MAP: Extending Parallel Sets for Visualizing Mixed Data</a></strong><br><a href=/website/people/S/Shisong-Wang/>Shisong Wang</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>
|
<a href=/website/people/S/S-Sadri/>S. Sadri</a>
|
<a href=/website/people/C/C-Roy/>C. Roy</a>
|
<a href=/website/people/J/J-Famiglietti/>J. Famiglietti</a>
|
<a href=/website/people/K/Kevin-A-Schneider/>Kevin A. Schneider</a><br><a href=/website/volumes/G22-1/ class=text-muted>Global Water Futures 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G22-1014><div class="card-body p-3 small">Multi-attribute dataset visualizations are often designed based on attribute types, i.e., whether the attributes are categorical or numerical. Parallel Sets and Parallel Coordinates are two well-known techniques to visualize categorical and numerical data, respectively. A common strategy to visualize mixed data is to use multiple information linked view, e.g., Parallel Coordinates are often augmented with maps to explore spatial data with numeric attributes. In this paper, we design visualizations for mixed data, where the dataset may include numerical, categorical, and spatial attributes. The proposed solution SET-STAT-MAP is a harmonious combination of three interactive components: Parallel Sets (visualizes sets determined by the combination of categories or numeric ranges), statistics columns (visualizes numerical summaries of the sets), and a geospatial map view (visualizes the spatial information). We augment these components with colors and textures to enhance users' capability of analyzing distributions of pairs of attribute combinations. To improve scalability, we merge the sets to limit the number of possible combinations to be rendered on the display. We demonstrate the use of Set-stat-map using two different types of datasets: a meteorological dataset and an online vacation rental dataset (Airbnb). To examine the potential of the system, we collaborated with the meteorologists, which revealed both challenges and opportunities for Set-stat-map to be used for real-life visual analytics.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2021.GWF-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G21-1014.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G21-1014/>Putting Table Cartograms into Practice</a></strong><br><a href=/website/people/M/M-Zahid-Hasan/>M Zahid Hasan</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>
|
<a href=/website/people/J/Jarin-Tasnim/>Jarin Tasnim</a>
|
<a href=/website/people/K/Kevin-A-Schneider/>Kevin A. Schneider</a><br><a href=/website/volumes/G21-1/ class=text-muted>Global Water Futures 2021</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2020.GWF-1.112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G20-1112.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G20-1112 data-toggle=collapse aria-expanded=false aria-controls=abstract-G20-1112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G20-1112/>Tracing shapes with eyes: design and evaluation of an eye tracking based approach</a></strong><br><a href=/website/people/M/Mohammad-Rakib-Hasan/>Mohammad Rakib Hasan</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>
|
<a href=/website/people/C/C-Gutwin/>C. Gutwin</a><br><a href=/website/volumes/G20-1/ class=text-muted>Global Water Futures 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G20-1112><div class="card-body p-3 small">Eye tracking systems can provide people with severe motor impairments a way to communicate through gaze-based interactions. Such systems transform a user's gaze input into mouse pointer coordinates that can trigger keystrokes on an on-screen keyboard. However, typing using this approach requires large back-and-forth eye movements, and the required effort depends both on the length of the text and the keyboard layout. Motivated by the idea of sketch-based image search, we explore a gaze-based approach where users draw a shape on a sketchpad using gaze input, and the shape is used to search for similar letters, words, and other predefined controls. The sketch-based approach is area efficient (compared to an on-screen keyboard), allows users to create custom commands, and creates opportunities for gaze-based authentication. Since variation in the drawn shapes makes the search difficult, the system can show a guide (e.g., a 14-segment digital display) on the sketchpad so that users can trace their desired shape. In this paper, we take a first step that investigates the feasibility of the sketch-based approach, by examining how well users can trace a given shape using gaze input. We designed an interface where participants traced a set of given shapes. We then compared the similarity of the drawn and traced shapes. Our study results show the potential of the sketch-based approach: users were able to trace shapes reasonably well using gaze input, even for complex shapes involving three letters; shape tracing accuracy for gaze was better than `free-form' hand drawing. We also report on how different shape complexities influence the time and accuracy of the shape tracing tasks.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2019.GWF-1.71.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G19-1071.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G19-1071/>Simplified Emanation Graphs: A Sparse Plane Spanner with Steiner Points</a></strong><br><a href=/website/people/B/Bardia-Hamedmohseni/>Bardia Hamedmohseni</a>
|
<a href=/website/people/Z/Zahed-Rahmati/>Zahed Rahmati</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a><br><a href=/website/volumes/G19-1/ class=text-muted>Global Water Futures 2019</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2019.GWF-1.135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G19-1135.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G19-1135/>Clone-World: A visual analytic system for large scale software clones</a></strong><br><a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>
|
<a href=/website/people/M/Manishankar-Mondal/>Manishankar Mondal</a>
|
<a href=/website/people/C/C-Roy/>C. Roy</a>
|
<a href=/website/people/K/Kevin-A-Schneider/>Kevin A. Schneider</a>
|
<a href=/website/people/Y/Yukun-Li/>Yukun Li</a>
|
<a href=/website/people/S/Shisong-Wang/>Shisong Wang</a><br><a href=/website/volumes/G19-1/ class=text-muted>Global Water Futures 2019</a></span></p><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://mobehbooei.github.io/website/2017.GWF-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/website/G17-1027.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/website/G17-1027/>On Compatible Triangulations with a Minimum Number of Steiner Points</a></strong><br><a href=/website/people/A/A-Lubiw/>A. Lubiw</a>
|
<a href=/website/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a><br><a href=/website/volumes/G17-1/ class=text-muted>Global Water Futures 2017</a></span></p></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Debajyoti+Mondal" title="Search for 'Debajyoti Mondal' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/website/people/K/Kevin-A-Schneider/ class=align-middle>Kevin A. Schneider</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/website/people/C/C-Roy/ class=align-middle>C. Roy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/website/people/S/Shisong-Wang/ class=align-middle>Shisong Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/website/people/A/A-Lubiw/ class=align-middle>A. Lubiw</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/B/Bardia-Hamedmohseni/ class=align-middle>Bardia Hamedmohseni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/website/people/Z/Zahed-Rahmati/ class=align-middle>Zahed Rahmati</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/M/Manishankar-Mondal/ class=align-middle>Manishankar Mondal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/Y/Yukun-Li/ class=align-middle>Yukun Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/M/Mohammad-Rakib-Hasan/ class=align-middle>Mohammad Rakib Hasan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/C/C-Gutwin/ class=align-middle>C. Gutwin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/M/M-Zahid-Hasan/ class=align-middle>M Zahid Hasan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/J/Jarin-Tasnim/ class=align-middle>Jarin Tasnim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/S/Shamse-Tasnim-Cynthia/ class=align-middle>Shamse Tasnim Cynthia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/B/B-Roy/ class=align-middle>B. Roy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/S/S-Sadri/ class=align-middle>S. Sadri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/website/people/J/J-Famiglietti/ class=align-middle>J. Famiglietti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/website/venues/gwf/ class=align-middle>GWF</a><span class="badge badge-secondary align-middle ml-2">7</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-light py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5"><div class=container><p class="text-muted small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="text-muted small px-1">The ACL Anthology is managed and built by the <a href=/website/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="text-muted small px-1"><i>Site last built on 17 November 2022 at 01:58 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/51de55f083dd8e08971d5f9d4a69e24f90b89cf2>commit 51de55f0</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script><script>$(function(){$('[data-toggle="tooltip"]').tooltip();if($("#toggle-all-abstracts")){$("#toggle-all-abstracts").click(function(){var target=$("#toggle-all-abstracts");target.attr("disabled",true);if(target.attr("data-toggle-state")=="hide"){$(".abstract-collapse").collapse('show');target.attr("data-toggle-state","show");}else{$(".abstract-collapse").collapse('hide');target.attr("data-toggle-state","hide");}
target.attr("disabled",false);});$("#toggle-all-abstracts").attr("disabled",false);}})</script></body></html>